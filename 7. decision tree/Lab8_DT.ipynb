{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS/CMPSC 410 Sparing 2021\n",
    "## Instructor: Professor John Yen\n",
    "## TA: Rupesh Prajapati and Dongkuan Xu\n",
    "## Lab 8 Decision Tree Learning Using MLlib and Visualization\n",
    "\n",
    "## The goals of this lab are for you to be able to\n",
    "- Understand the function of the different steps/stages involved in Spark ML pipeline\n",
    "- Be able to construct a decision tree using Spark ML machine learning module\n",
    "- Be able to generate a visualization of Decision Trees\n",
    "- Be able to compare and evaluate Decision Tree models created using different hyper-parameters (e.g., maximum tree depth)\n",
    "\n",
    "## The data set used in this lab is a Breast Cancer diagnosis dataset.\n",
    "\n",
    "## Submit the following items for Lab 8 (DT)\n",
    "- Completed Jupyter Notebook of Lab 8 (in HTML or PDF format)\n",
    "- A word or PDF file that includes the two visualization of decision trees and answers to Exercise 4.\n",
    "\n",
    "## Total Number of Exercises: 4\n",
    "- Exercise 1: 5 points\n",
    "- Exercise 2: 5 points\n",
    "- Exercise 3: 20 points  \n",
    "- Exercise 4: 30 points (Word or PDF file)\n",
    "## Total Points: 60 points\n",
    "\n",
    "# Due: midnight, March 26 (Friday), 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set up the Python files for decision tree visualizations\n",
    "1. Create a \"Lab8DT\" directory in the work directory of your ICDS-ROAR home directory.\n",
    "2. If you have not done so, copy or upload this file to the \"Lab8DT\" directory.\n",
    "3. Create a subdirectory under \"Lab8DT\" called \"decision_tree_plot\" (named the directory EXACTLY this way).\n",
    "4. Upload the following three files in Module 8 from Canvas to the decision_tree_plot directory\n",
    "- decision_tree_parser.py\n",
    "- decision_tree_plot.py\n",
    "- tree_template.jinjia2\n",
    "\n",
    "### Follow the instructions below and execute the PySpark code cell by cell below. Make modifications as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice that we use PySpark SQL module to import SparkSession because ML works with SparkSession\n",
    "## Notice also the different methods imported from ML and three submodules of ML: classification, feature, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following two lines import relevant functions from the two python files you uploaded into the decision_tree_plot subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree_plot.decision_tree_parser import decision_tree_parse\n",
    "from decision_tree_plot.decision_tree_plot import plot_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This lab runs Spark in the local mode.\n",
    "## Notice we are creating a SparkSession, not a SparkContext, when we use ML pipeline.\n",
    "## The \"getOrCreate()\" method means we can re-evaluate this without a need to \"stop the current SparkSession\" first (unlike SparkContext)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=SparkSession.builder.master(\"local\").appName(\"lab 8 DT\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we have seen in Lab 4, SparkSession offers a way to read a CSV/text file with the capability to interpret the first row as being the header and infer the type of different columns based on their values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: (5 points) Complete the following path with the path for your home directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ss.read.csv(\"/storage/home/???/Lab8DT/breast-cancer-wisconsin.data.txt\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: (5 points) Enter your name below:\n",
    "- My Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomSplit is a method for DataFrame that split data in the DataFrame into two subsets, one for training, the other for testing, using a number as the seed for random number generator.\n",
    "## If you want to generate a different split, you can use a different seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData= data.randomSplit([0.7, 0.3], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"class\", outputCol=\"indexedLabel\").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnIndexer = StringIndexer(inputCol=\"bare_nuclei\", outputCol=\"bare_nuclei_index\").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['clump_thickness', 'unif_cell_size', 'unif_cell_shape', 'marg_adhesion', 'single_epith_cell_size', 'bland_chrom', 'norm_nucleoli', 'mitoses', 'bare_nuclei_index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: (10 points) Choose two different values for maxDepth hyperparameter of Decision Trees. (Recommended value for maxDepth: 2 to 7). Run the entire sequence of code below to generate two decision trees. \n",
    "- Record the f1 measure for each max_depth below  \n",
    "- Make sure you CHANGE the name of the files for saving decision trees (e.g., \"DTtree_d3.html\", \"DTtree_d5.html\", ...). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for Exercise 3: \n",
    "- f1 measure for max_detph ??? = ???\n",
    "- f1 measure for max_depth ??? = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler( inputCols=input_features, outputCol=\"features\")\n",
    "dt=DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", maxDepth=???, minInstancesPerNode=2)\n",
    "labelConverter = IndexToString(inputCol=\"indexedLabel\", outputCol=\"predictedClass\", labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[labelIndexer, bnIndexer, assembler, dt, labelConverter])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluator.evaluate(predictions)\n",
    "print(\"f1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stages[3] of the pipeline is \"dt\" (DecisionTreeClassifier).  stages[0] is labelIndexer.\n",
    "## model is a DataFrame representing a trained pipeline.\n",
    "## model.stages[3] gives us the Decision Tree model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTmodel = model.stages[3]\n",
    "print(DTmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"./DTmodel_vis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a file name for your decision tree below.  If your PySpark code runs successfully, you should see your DT visualization file (e.g., DTtree_d3.html) in your Lab8DT directory.  \n",
    "### Note: Change the name of your file before you run the code above with a different maxDepth hyperparameter value. \n",
    "### Download the two decision tree visualization files.  Open them with a browser, you will see the trees.\n",
    "### Use screen capture tool (e.g., sreenshot in Mac, snipping tool in PC) to capture the decision trees, and include them in your word document for answers to Exercise 4 (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree=decision_tree_parse(DTmodel, ss, model_path)\n",
    "column = dict([(str(idx), i) for idx, i in enumerate(input_features)])\n",
    "plot_trees(tree, column = column, output_path = '????.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: (30 points) Use a word document to \n",
    "- (a) Show the decision tree visualization for the two values of max_depth (10 points)\n",
    "- (b) Discuss the key difference between the two trees. (10 points)\n",
    "- (c) Discuss which tree you believe is a better model for breast cancer diagnosis, and explain the rationale of your choice. (10 points)\n",
    "### Submit the PDF version of the word document as a part of this lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
